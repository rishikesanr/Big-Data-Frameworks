{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83cfa22a-dee4-48f8-8e4e-933807b9e033",
   "metadata": {},
   "source": [
    "# MlFlow with Databricks \n",
    "\n",
    "With Community edition, only until Model Tracking is accessible, so for Model Registry commerical edition may have to be obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc79c500-a54f-431f-befa-9dc65c26e874",
   "metadata": {},
   "source": [
    "## Data Versioning with Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ae1f1c-100d-499f-b9bf-c775227c44d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = f\"{DA.paths.datasets}/airbnb/sf-listings/sf-listings-2019-03-06-clean.delta/\"\n",
    "airbnb_df = spark.read.format(\"delta\").load(file_path)\n",
    "\n",
    "train_df, test_df = airbnb_df.randomSplit([.8, .2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b4e0e-72a0-4f55-a2e6-49ad84083538",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_delta_path = f\"{DA.paths.working_dir}/train.delta\"\n",
    "test_delta_path = f\"{DA.paths.working_dir}/test.delta\"\n",
    "\n",
    "# In case paths already exists\n",
    "dbutils.fs.rm(train_delta_path, True)\n",
    "dbutils.fs.rm(test_delta_path, True)\n",
    "\n",
    "train_df.write.mode(\"overwrite\").format(\"delta\").save(train_delta_path)\n",
    "test_df.write.mode(\"overwrite\").format(\"delta\").save(test_delta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a904a5-7fe6-450a-a5f9-7afe16919e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = 0\n",
    "train_delta = spark.read.format(\"delta\").option(\"versionAsOf\",data_version).load(train_delta_path)\n",
    "test_delta = spark.read.format(\"delta\").option(\"versionAsOf\",data_version).load(test_delta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aabb36bd-8a29-43dd-849c-364e816013a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the transactions of thie Delta table\n",
    "display(spark.sql(f\"DESCRIBE HISTORY delta.`{train_delta_path}`\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ccb8cc-904d-4ff6-96eb-7da2cc01b61e",
   "metadata": {},
   "source": [
    "## MLflow Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c311c68-818d-41b9-9b63-778837703802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "import mlflow\n",
    "import mlflow.spark\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "with mlflow.start_run(run_name=\"lr_model\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"data_path\", train_delta_path)  \n",
    "    # TODO: Log label: price-all-features\n",
    "    mlflow.log_param(\"label\",\"price-all-features\")\n",
    "    # TODO: Log data_version: data_version\n",
    "    mlflow.log_param(\"data_version\", data_version)\n",
    "\n",
    "\n",
    "    # Create pipeline\n",
    "    r_formula = RFormula(formula=\"price ~ .\", featuresCol=\"features\", labelCol=\"price\", handleInvalid=\"skip\")\n",
    "    lr = LinearRegression(labelCol=\"price\", featuresCol=\"features\")\n",
    "    pipeline = Pipeline(stages = [r_formula, lr])\n",
    "    model = pipeline.fit(train_delta)\n",
    "\n",
    "    # Log pipeline\n",
    "    # TODO: Log model: model\n",
    "    mlflow.spark.log_model(model,\"model\")\n",
    "\n",
    "    # Create predictions and metrics\n",
    "    pred_df = model.transform(test_delta)\n",
    "    regression_evaluator = RegressionEvaluator(labelCol=\"price\", predictionCol=\"prediction\")\n",
    "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(pred_df)\n",
    "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(pred_df)\n",
    "\n",
    "    # Log metrics\n",
    "    # TODO: Log RMSE\n",
    "    mlflow.log_metric(\"rmse\",rmse)\n",
    "    # TODO: Log R2\n",
    "    mlflow.log_metric(\"r2\",r2)\n",
    "\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4d9ca2-614c-470a-a520-2c31d187a029",
   "metadata": {},
   "source": [
    "## Register Model with Model Registry and Move it to Staging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab65916-7904-4547-b627-7effabfdf576",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = f\"runs:/{run_id}/model\"\n",
    "\n",
    "suffix = DA.unique_name(\"-\")\n",
    "model_name = f\"mllib-lr_{suffix}\"\n",
    "print(f\"Model Name: {model_name}\\n\")\n",
    "\n",
    "model_details = mlflow.register_model(model_uri=model_uri, name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "258fa4a0-e27b-476b-baf4-ab717c52000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transition model to staging \n",
    "\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "client = MlflowClient()\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=1,\n",
    "    stage=\"Staging\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b18a807-49c5-44ee-8598-7d3f0f282007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are automating \n",
    "\n",
    "# Define a utility method to wait until the model is ready\n",
    "def wait_for_model(model_name, version, stage=\"None\", status=\"READY\", timeout=300):\n",
    "    import time\n",
    "\n",
    "    last_stage = \"unknown\"\n",
    "    last_status = \"unknown\"\n",
    "\n",
    "    for i in range(timeout):\n",
    "        model_version_details = client.get_model_version(name=model_name, version=version)\n",
    "        last_stage = str(model_version_details.current_stage)\n",
    "        last_status = str(model_version_details.status)\n",
    "        if last_status == str(status) and last_stage == str(stage):\n",
    "            return\n",
    "\n",
    "        time.sleep(1)\n",
    "\n",
    "    raise Exception(f\"The model {model_name} v{version} was not {status} after {timeout} seconds: {last_status}/{last_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ef39c-e327-4796-b206-e9861fc97a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force our notebook to block until the model is ready. Useful when the scripts are running\n",
    "wait_for_model(model_name, 1, stage=\"Staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48dd1b9-7e28-4a68-9f0a-d35523834745",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add a model description \n",
    "\n",
    "client.update_registered_model(\n",
    "  name=model_name,\n",
    "  description=\"This model uses Airbnb data and rformula to make a spark linear regression.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7168b53-fa77-49b9-8c5a-3e247465b3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_model(model_details.name, 1, stage=\"Staging\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb5d2e9-4f48-4c24-bc96-da986e7c65b8",
   "metadata": {},
   "source": [
    "## Feature Engineering & Data Version Tracking with Delta Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47c3f0-bbf9-4863-9e01-1affa9a71b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add log price\n",
    "\n",
    "from pyspark.sql.functions import col, log, exp\n",
    "\n",
    "# Create a new log_price column for both train and test datasets\n",
    "train_new = train_delta.withColumn(\"log_price\", log(col(\"price\")))\n",
    "test_new = test_delta.withColumn(\"log_price\", log(col(\"price\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515e14bb-b511-41dc-bc4f-2583944a75d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_new.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(train_delta_path)\n",
    "train_new.write.mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(test_delta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80af3e3-8db4-4145-8f73-295b44021084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the difference between original and modified schemas \n",
    "\n",
    "set(train_new.schema.fields) ^ set(train_delta.schema.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8802050e-03a0-4fc5-9382-e40e41270667",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review the histroy of our delta table \n",
    "display(spark.sql(f\"DESCRIBE HISTORY delta.`{train_delta_path}`\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6badef9c-a66a-4d27-b4de-c437e2f953e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = 1\n",
    "train_delta_new = spark.read.format(\"delta\").option(\"versionAsOf\", data_version).load(train_delta_path)  \n",
    "test_delta_new = spark.read.format(\"delta\").option(\"versionAsOf\", data_version).load(test_delta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa33e67b-8dc3-48c7-ad99-c83411c29d44",
   "metadata": {},
   "source": [
    "## Use Log Price Model and Track Run with MLFlow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922a8cfe-8914-43aa-afde-f3f232327737",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"lr_log_model\") as run:\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"label\", \"log-price\")\n",
    "    mlflow.log_param(\"data_version\", data_version)\n",
    "    mlflow.log_param(\"data_path\", train_delta_path)    \n",
    "\n",
    "    # Create pipeline\n",
    "    r_formula = RFormula(formula=\"log_price ~ . - price\", featuresCol=\"features\", labelCol=\"log_price\", handleInvalid=\"skip\")  \n",
    "    lr = LinearRegression(labelCol=\"log_price\", predictionCol=\"log_prediction\")\n",
    "    pipeline = Pipeline(stages = [r_formula, lr])\n",
    "    pipeline_model = pipeline.fit(train_delta_new)\n",
    "\n",
    "    # Log model and update the registered model\n",
    "    mlflow.spark.log_model(\n",
    "        spark_model=pipeline_model,\n",
    "        artifact_path=\"log-model\",\n",
    "        registered_model_name=model_name\n",
    "    )  \n",
    "\n",
    "    # Create predictions and metrics\n",
    "    pred_df = pipeline_model.transform(test_delta)\n",
    "    exp_df = pred_df.withColumn(\"prediction\", exp(col(\"log_prediction\")))\n",
    "    rmse = regression_evaluator.setMetricName(\"rmse\").evaluate(exp_df)\n",
    "    r2 = regression_evaluator.setMetricName(\"r2\").evaluate(exp_df)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"rmse\", rmse)\n",
    "    mlflow.log_metric(\"r2\", r2)  \n",
    "\n",
    "    run_id = run.info.run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6293eff6-3799-4041-b161-a1a4c5a306ec",
   "metadata": {},
   "source": [
    "## Compare performance across model runs based on Data Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d767808e-1699-4982-80b3-b9b0fa895629",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version 0\n",
    "\n",
    "data_version = 0\n",
    "\n",
    "mlflow.search_runs(filter_string=f\"params.data_version='{data_version}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfcb42-11f6-4df5-84d4-32d839c0c020",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_version = 1\n",
    "\n",
    "mlflow.search_runs(filter_string=f\"params.data_version='{data_version}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644d9543-6d7d-41e3-851f-2ca34462c8c8",
   "metadata": {},
   "source": [
    "## Move the best model to Production (Basics of CI/CD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc0d3c6-2791-4090-9795-6dec067415c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the most recent model version and move to production. In this case, we know model with log price was better due to low rmse, however \n",
    "#can be checked as one of the testing criteria for the model with the lowest rmse (or similar metric) before moving it into production \n",
    "model_version_infos = client.search_model_versions(f\"name = '{model_name}'\")\n",
    "new_model_version = max([model_version_info.version for model_version_info in model_version_infos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf605796-059b-4fae-9d07-7d05e56f242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=new_model_version,\n",
    "    description=\"This model version was built using a MLlib Linear Regression model with all features and log_price as predictor.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e318a7-f6a5-4519-974a-8a4b899f043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_version_details = client.get_model_version(name=model_name, version=new_model_version)\n",
    "model_version_details.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f168621-6267-487f-bfa2-9c6042dda8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move Model into Production\n",
    "client.transition_model_version_stage(\n",
    "  model=model_name,\n",
    "  version=new_model_version,\n",
    "  stage='production',\n",
    "  archive_existing_versions=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df315806-968d-4a09-875c-d116e6cfb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "wait_for_model(model_name, new_model_version, \"Production\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:epl_analytics] *",
   "language": "python",
   "name": "conda-env-epl_analytics-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
