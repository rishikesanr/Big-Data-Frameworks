# -*- coding: utf-8 -*-
"""Copy of Spark_Tasmania.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1u6XyjoOnGeyQZMpyz2aApC1iOlYhmAry
"""

import os
from pyspark.sql import SparkSession
# Define Java and Spark home path in Google Colab
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.4.1-bin-hadoop3"

from pyspark.sql import SparkSession

# from pyspark import SparkConf, SparkContext
from datetime import datetime, date, timedelta
from dateutil import relativedelta
from pyspark.sql import SQLContext, Row
from pyspark.sql.types import *
from pyspark.sql import DataFrame
from pyspark.sql.functions import *
from pyspark.sql.functions import to_timestamp, to_date
from pyspark.sql import functions as F
from pyspark.sql.functions import collect_list, collect_set, concat, first, array_distinct, col, size, expr
import random

# Initialize a SparkSession
spark = SparkSession.builder \
    .appName("Linear Regression in Spark") \
    .getOrCreate()


temp = spark.read.csv("gs://dataproc-staging-us-west1-369617492652-pgeoxami/temp.csv", inferSchema = True, header = True)

temp.printSchema()

temp.show(5)

temp.describe()

spark.conf.set("spark.sql.shuffle.partitions", "10")

#Create dataframe into a table or view
temp.createOrReplaceTempView("temp_table")

#SQL vs Dataframe in Spark

# sqlWay = spark.sql("""
# SELECT Country, EXTRACT(YEAR FROM dt) as year, AVG(AverageTemperature) as avg_temp
# FROM temp_table
# GROUP BY Country, EXTRACT(YEAR FROM dt)
# order by 3 desc limit 1
# """)

from pyspark.sql.functions import year, avg, col


df_result = temp.groupBy("Country", year("dt").alias("year")) \
    .agg(avg("AverageTemperature").alias("avg_temp")) \
    .orderBy(col("avg_temp").desc()) \
    .limit(1)

df_result.show()

from pyspark.sql.functions import year, avg, col, max, min

#Calculating average temperature per year per country
temp_by_year_country = temp.groupBy("Country", year("dt").alias("year")) \
    .agg(avg("AverageTemperature").alias("avg_temp"))

#Calculating the max and min average temperature for each country
temp_range_by_country = temp_by_year_country.groupBy("Country") \
    .agg(
        (max("avg_temp") - min("avg_temp")).alias("temp_change")
    )

#Ordering by the temperature change in descending order and limit to top 10
top_countries_by_temp_change = temp_range_by_country.orderBy(col("temp_change").desc()) \
    .limit(10)

top_countries_by_temp_change.show()

# Read the CO2 emissions data

CO2_data = spark\
.read\
.option("inferSchema", "true")\
.option("header", "true")\
.csv("gs://dataproc-staging-us-west1-369617492652-pgeoxami/emissions.csv")

from pyspark.sql.types import StructType, StructField, StringType, DoubleType
from pyspark.sql.functions import lit, col

schema = StructType(\
 [StructField('Country Name', StringType(), True),\
  StructField('Country Code', StringType(), True),\
  StructField('CO2_Emissions', DoubleType(), True),\
  StructField('Year', StringType(), False)])

emissions_final = spark.createDataFrame([], schema = schema)

year_list = []
for i in list((range(1960,2015))):
  year_list.append(str(i))

for i in year_list:
  filtered_df = CO2_data.select("Country Name","Country Code",i).withColumn("Year",lit(i))
  filtered_df = filtered_df.withColumnRenamed(i, "CO2_Emissions")
  emissions_final = emissions_final.union(filtered_df)

emissions_final.show()

#Calculating change in temperature per year per country (range)
temp_change_by_year_country = temp.groupBy("Country", year("dt").alias("year")) \
    .agg(
        (max("AverageTemperature") - min("AverageTemperature")).alias("temp_change")
    )

temp_change_by_year_country.show()

from pyspark.sql.functions import year, col


emissions_final = emissions_final.withColumnRenamed("Country Name", "Country")
temp_change_by_year_country = temp_change_by_year_country.withColumnRenamed("year", "Year")

# Filtering the datasets by year (now using the added 'Year' column for consistency)
temp_df_filtered = temp_change_by_year_country.filter((col("Year") >= "1960") & (col("Year") <= "2014"))
emissions_df_filtered = emissions_final.filter((col("Year") >= "1960") & (col("Year") <= "2014"))



# Merge the datasets
# Ensure 'Country' and 'Year' are present and correctly named in both DataFrames
merged_df = temp_df_filtered.join(emissions_df_filtered, ["Country", "Year"], "inner")

merged_df.show()

corr_value = merged_df.corr('temp_change','CO2_Emissions')

print("\n Correlation between temperature change and CO2 emissions is",corr_value,". It is based on per country per year data aggregation.")